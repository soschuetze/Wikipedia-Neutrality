{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Wikipedia API to obtain featured and non-featured articles\n",
    "To study the difference in sentiment of featured and non-featured articles, a set of 75 articles from each category was obtained. For featured articles, the Wikipedia API was used to obtain a list of article names within the featured articles category. 75 random titles were then chosen from this list. For non-featured articles, the random function of the Wikipedia API was used to obtain an additional 75 articles. For each of the 125 total articles, the total content of the article was obtained as well as the page summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "#set seed so same results will be displayed each time it's run\n",
    "random.seed(1)\n",
    "#get links of pages contained in featured articles category\n",
    "all_featured_articles = wikipedia.WikipediaPage(title = \"Wikipedia:Featured_articles\").links\n",
    "#get random sample of 75 featured articles\n",
    "featured_article_titles = random.sample(all_featured_articles, 75)\n",
    "featured_art_dict = dict.fromkeys(featured_article_titles)\n",
    "non_featured_article_titles = []\n",
    "\n",
    "#get 75 random wikipedia articles that aren't featured articles\n",
    "while len(non_featured_article_titles) < 75:\n",
    "    random_page = wikipedia.random()\n",
    "    \n",
    "    # make sure not already in list and no in featured articles\n",
    "    if random_page not in non_featured_article_titles and random_page not in all_featured_articles:\n",
    "        non_featured_article_titles.append(random_page)\n",
    "\n",
    "non_featured_art_dict = dict.fromkeys(non_featured_article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(article_titles, art_dict):\n",
    "    '''\n",
    "    For each article title, get content and summary from Wikipedia page and return dictionary with that information\n",
    "    '''\n",
    "    for p in article_titles:\n",
    "        try:\n",
    "            page = wikipedia.WikipediaPage(p)\n",
    "            content = page.content\n",
    "            summary = page.summary\n",
    "            \n",
    "        #occurs when multiple wikipedia pages have same beginning of page title\n",
    "        except wikipedia.DisambiguationError as e:\n",
    "            pass\n",
    "\n",
    "        art_dict[p] = {\"content\": content,\n",
    "                      \"summary\":summary}\n",
    "        \n",
    "    return art_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframes of Featured and Non-featured Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_art_dict = get_content(featured_article_titles, featured_art_dict)\n",
    "non_featured_art_dict = get_content(non_featured_article_titles, non_featured_art_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with page content and summary information\n",
    "featured_df = pd.DataFrame.from_dict(featured_art_dict, orient='index')\n",
    "non_featured_df = pd.DataFrame.from_dict(non_featured_art_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove of references and bibliography sections\n",
    "featured_df['content_cleaned'] = featured_df['content'].apply(lambda x: x.split(\"References\")[0])\n",
    "non_featured_df['content_cleaned'] = non_featured_df['content'].apply(lambda x: x.split(\"References\")[0])\n",
    "\n",
    "#clean unnecessary characters\n",
    "featured_df['content_cleaned'] = featured_df['content_cleaned'].replace(r'(\\\\n)|=|(\\\\)', '', regex=True)\n",
    "non_featured_df['content_cleaned'] = non_featured_df['content_cleaned'].replace(r'(\\\\n)|=|(\\\\)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text, stopWords):\n",
    "    '''\n",
    "    Removes stopwords from given line of text and returns cleaned text\n",
    "    '''\n",
    "    cleaned_text = ' '.join([word for word in text.split() if word not in stopwords.words(\"english\")])\n",
    "    return cleaned_text\n",
    "\n",
    "featured_df['content_cleaned'] = featured_df['content_cleaned'].apply(lambda x: remove_stopwords(x, stopWords))\n",
    "non_featured_df['content_cleaned'] = non_featured_df['content_cleaned'].apply(lambda x: remove_stopwords(x, stopWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Sentiment and Making Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "featured_df['sentiment_score_all'] = 0\n",
    "non_featured_df['sentiment_score_all'] = 0\n",
    "\n",
    "featured_df['sentiment_score_sum'] = 0\n",
    "non_featured_df['sentiment_score_sum'] = 0\n",
    "\n",
    "def sentiment_scores(sentence):\n",
    "    '''\n",
    "    Use Vader Sentiment model to return neutral sentiment score for a given sentence\n",
    "    '''\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
    "    \n",
    "    return sentiment_dict['neu']\n",
    "        \n",
    "#get sentiment scores for entire text and summary\n",
    "featured_df['sentiment_score_all'] = featured_df['content_cleaned'].apply(lambda x: sentiment_scores(x))\n",
    "non_featured_df['sentiment_score_all'] = non_featured_df['content_cleaned'].apply(lambda x: sentiment_scores(x))\n",
    "\n",
    "featured_df['sentiment_score_sum'] = featured_df['summary'].apply(lambda x: sentiment_scores(x))\n",
    "non_featured_df['sentiment_score_sum'] = non_featured_df['summary'].apply(lambda x: sentiment_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_t_test(group_1, group_2):\n",
    "    '''\n",
    "    Conduct a t test comparing two arrays and print statement about significance depending on resulting p-value\n",
    "    '''\n",
    "    dof = min(len(group_1),len(group_2)) - 1\n",
    "    t_stat, p_val = stats.ttest_ind(group_1, group_2, equal_var = False) \n",
    "    alpha = 0.05\n",
    "    group1_avg = np.average(group_1)\n",
    "    group2_avg = np.average(group_2)\n",
    "    print(f\"Featured pages avg: {group1_avg:.3f}\")\n",
    "    print(f\"Non Featured pages avg: {group2_avg:.3f}\")\n",
    "    print(f\"Difference in Means: {group1_avg - group2_avg:.2f}\")\n",
    "    print(f\"DF: {dof}\")\n",
    "    print(f\"T-stat: {t_stat:.2f}\")\n",
    "    print(f\"P-value: {p_val:.2f}\")\n",
    "    if p_val < alpha:\n",
    "        print(\"Reject the null hypothesis; there is a significant difference.\")\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis; there is no significant difference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct t-test between neutral scores of entire text of featured vs. non-featured pages\n",
    "featured_values = featured_df['sentiment_score_all'].tolist()\n",
    "non_featured_values = non_featured_df['sentiment_score_all'].tolist()\n",
    "conduct_t_test(featured_values, non_featured_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conduct t-test between neutral scores of summary of featured vs. non-featured pages\n",
    "featured_values_sum = featured_df['sentiment_score_sum'].tolist()\n",
    "non_featured_values_sum = non_featured_df['sentiment_score_sum'].tolist()\n",
    "conduct_t_test(featured_values_sum, non_featured_values_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df['type'] = \"Featured Pages\"\n",
    "non_featured_df['type'] = \"Non-Featured Pages\"\n",
    "total_df = pd.concat([featured_df, non_featured_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create two histograms, one for featured and one for non-featured pages, of number of pages by neutral sentiment score\n",
    "def hist_plot_1():\n",
    "    from matplotlib.ticker import StrMethodFormatter\n",
    "    ax = total_df.hist(column='sentiment_score_sum', by='type', bins=10, grid=False, figsize=(8,10), layout=(3,1), sharex=True, color='#2d76ba', zorder=2, rwidth=0.9)\n",
    "\n",
    "    for i,x in enumerate(ax):\n",
    "\n",
    "        # Despine\n",
    "        x.spines['right'].set_visible(False)\n",
    "        x.spines['top'].set_visible(False)\n",
    "        x.spines['left'].set_visible(False)\n",
    "\n",
    "        # Switch off ticks\n",
    "        x.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\", labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "        # Draw horizontal axis lines\n",
    "        vals = x.get_yticks()\n",
    "        for tick in vals:\n",
    "            x.axhline(y=tick, linestyle='dashed', alpha=0.4, color='#eeeeee', zorder=1)\n",
    "\n",
    "        # Set x-axis label\n",
    "        x.set_xlabel(\"Neutral Sentiment Score of Summary\", labelpad=20, weight='bold', size=12)\n",
    "\n",
    "        # Set y-axis label\n",
    "        x.set_ylabel(\"Number of Pages\", labelpad=50, weight='bold', size=12)\n",
    "\n",
    "        # Format y-axis label\n",
    "        x.yaxis.set_major_formatter(StrMethodFormatter('{x:,g}'))\n",
    "\n",
    "        x.tick_params(axis='x', rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons by Length of Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column with length of cleaned text\n",
    "featured_df['length'] = featured_df['content_cleaned'].apply(lambda x: len(x.split()))\n",
    "non_featured_df['length'] = non_featured_df['content_cleaned'].apply(lambda x: len(x.split()))\n",
    "\n",
    "featured_len_values = featured_df['length'].tolist()\n",
    "non_featured_len_values = non_featured_df['length'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting average length by page type\n",
    "import statistics\n",
    "print(statistics.mean(featured_len_values))\n",
    "print(statistics.mean(non_featured_len_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get length of summary\n",
    "featured_df['length_sum'] = featured_df['summary'].apply(lambda x: len(x.split()))\n",
    "non_featured_df['length_sum'] = non_featured_df['summary'].apply(lambda x: len(x.split()))\n",
    "\n",
    "featured_len_sum = featured_df['length_sum'].tolist()\n",
    "non_featured_len_sum = non_featured_df['length_sum'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "def plot_fig(feature_sen_values, non_feature_sen_values, feature_len, non_feature_len, title): \n",
    "    '''\n",
    "    Create scatterplot of length of content vs. neutral sentiment score\n",
    "    '''\n",
    "    plt.scatter(feature_len, feature_sen_values, label = \"Featured Pages\")\n",
    "    plt.scatter(non_feature_len, non_feature_sen_values, label = \"Non Featured Pages\")\n",
    "    \n",
    "    plt.xlabel(\"Number of Words in Page Content\")\n",
    "    plt.ylabel(\"Compound Polarity Score\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Non-featured Posts with Length Similar to Featured Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min(featured_len_values)\n",
    "print(min_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_featured_article_long = []\n",
    "random.seed(4)\n",
    "\n",
    "#gets only non-featured pages whose length is at least equal to the minimum length of featured pages' content\n",
    "while len(non_featured_article_long) < 75:\n",
    "    random_page = wikipedia.random()\n",
    "    try:\n",
    "        content = wikipedia.WikipediaPage(random_page).content\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        pass\n",
    "        \n",
    "    page_length = len(content.split())\n",
    "    \n",
    "    #checks if greater than or equal to min length of featured pages\n",
    "    if random_page not in non_featured_article_long and random_page not in all_featured_articles and page_length >= min_length:\n",
    "        non_featured_article_long.append(random_page)\n",
    "\n",
    "non_featured_len_dict = dict.fromkeys(non_featured_article_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_featured_len_dict = get_content(non_featured_article_long, non_featured_len_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various text cleaning functions as used above\n",
    "non_featured_len_df = pd.DataFrame.from_dict(non_featured_len_dict, orient='index')\n",
    "non_featured_len_df['content_cleaned'] = non_featured_len_df['content'].apply(lambda x: x.split(\"References\")[0])\n",
    "non_featured_len_df['content_cleaned'] = non_featured_len_df['content_cleaned'].replace(r'(\\\\n)|=|(\\\\)', '', regex=True)\n",
    "non_featured_len_df['content_cleaned'] = non_featured_len_df['content_cleaned'].apply(lambda x: remove_stopwords(x, stopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Sentiment and Making Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_featured_len_df['sentiment_score_all'] = 0\n",
    "non_featured_len_df['sentiment_score_all'] = non_featured_len_df['content_cleaned'].apply(lambda x: sentiment_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_featured_len_values = non_featured_len_df['sentiment_score_all'].tolist()\n",
    "conduct_t_test(featured_values, non_featured_len_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_df['type'] = \"Featured Pages\"\n",
    "non_featured_len_df['type'] = \"Non-Featured Pages\"\n",
    "total_len_df = pd.concat([featured_df, non_featured_len_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot_2():\n",
    "    from matplotlib.ticker import StrMethodFormatter\n",
    "    ax = total_len_df.hist(column='sentiment_score_all', by='type', bins=10, grid=False, figsize=(8,10), layout=(3,1), sharex=True, color='#2d76ba', zorder=2, rwidth=0.9)\n",
    "\n",
    "    for i,x in enumerate(ax):\n",
    "\n",
    "        # Despine\n",
    "        x.spines['right'].set_visible(False)\n",
    "        x.spines['top'].set_visible(False)\n",
    "        x.spines['left'].set_visible(False)\n",
    "\n",
    "        # Switch off ticks\n",
    "        x.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\", labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "        # Draw horizontal axis lines\n",
    "        vals = x.get_yticks()\n",
    "        for tick in vals:\n",
    "            x.axhline(y=tick, linestyle='dashed', alpha=0.4, color='#eeeeee', zorder=1)\n",
    "\n",
    "        # Set x-axis label\n",
    "        x.set_xlabel(\"Neutral Sentiment Score of Text of Pages with Similar Lengths\", labelpad=20, weight='bold', size=12)\n",
    "\n",
    "        # Set y-axis label\n",
    "        x.set_ylabel(\"Number of Pages\", labelpad=50, weight='bold', size=12)\n",
    "\n",
    "        # Format y-axis label\n",
    "        x.yaxis.set_major_formatter(StrMethodFormatter('{x:,g}'))\n",
    "\n",
    "        x.tick_params(axis='x', rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_featured_len_df['length'] = non_featured_len_df['content_cleaned'].apply(lambda x: len(x.split()))\n",
    "non_featured_lengths = non_featured_len_df['length'].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
